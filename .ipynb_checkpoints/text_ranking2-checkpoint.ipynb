{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "006bae07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install PyKomoran\n",
    "# !pip install --upgrade PyKomoran\n",
    "import pandas as pd\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ee1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 불러오기\n",
    "with open('text.txt', 'r', encoding='cp949') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 불용어 리스트 만들기\n",
    "f=open('stopwords.txt','r',encoding='utf-8')\n",
    "stop_words = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea8ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1776c59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Komoran tokenizer\n",
    "okt = Okt()\n",
    "# Preprocessing function using KoNLPy2\n",
    "def preprocess_text(text, stop_words):\n",
    "    # Remove non-Korean characters and whitespace\n",
    "    text = re.sub(r'[^가-힣\\s]', '', text)\n",
    "    # Tokenize the text using Komoran\n",
    "    pos_tags = okt.pos(text)\n",
    "    filtered_words = [word for word, pos in pos_tags if pos in [\"Noun\", \"Adjective\", \"Verb\"]]\n",
    "    # Remove stopwords\n",
    "    words = [word for word in filtered_words if word not in stop_words]\n",
    "    return words\n",
    "\n",
    "preprocessed_words = preprocess_text(text, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "83789b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 그래프를 편집하는 함수\n",
    "def word_graph(sentence):\n",
    "    # Create a graph representation of the sentences\n",
    "    \n",
    "    for word in sentence:\n",
    "        graph.add_node(word)\n",
    "    for i in range(len(sentence)):\n",
    "        for j in range(i+1, len(sentence)):\n",
    "            word1, word2 = sentence[i], sentence[j]\n",
    "            if graph.has_edge(word1, word2):\n",
    "                graph[word1][word2]['weight'] += 1\n",
    "            else:\n",
    "                graph.add_edge(word1, word2, weight=1)\n",
    "                \n",
    "\n",
    "# 텍스트 랭킹 함수\n",
    "def text_ranking(graph,num_keywords=20, damping_factor=0.85, max_iter=100, tol=1e-4):\n",
    "\n",
    "    # PageRank algorithm to get keywords\n",
    "    pagerank_scores = nx.pagerank(graph, alpha=damping_factor, max_iter=max_iter, tol=tol)\n",
    "\n",
    "    # Sort the keywords based on their PageRank scores\n",
    "    keywords = sorted(pagerank_scores, key=pagerank_scores.get, reverse=True)[:num_keywords]\n",
    "    \n",
    "    return keywords\n",
    "\n",
    "\n",
    "# 그래프 생성\n",
    "graph = nx.Graph()\n",
    "\n",
    "word_graph(preprocessed_words)\n",
    "\n",
    "keywords = text_ranking(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02ad5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['사피', '스', '인간', '인류', '출', '간', '서문', '저자', '특별', '세계', '시대', '역사', '이해', '책', '더', '인공', '지능', '글', '이야기', '성과']\n"
     ]
    }
   ],
   "source": [
    "print(keywords)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2793aed",
   "metadata": {},
   "source": [
    "### 생각한대로 나오지는 않는다.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
