{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "006bae07",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip install PyKomoran\n",
    "# !pip install --upgrade PyKomoran\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from konlpy.tag import Okt\n",
    "import networkx as nx\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4ee1dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 파일 불러오기\n",
    "with open('text.txt', 'r', encoding='cp949') as file:\n",
    "    text = file.read()\n",
    "\n",
    "# 불용어 리스트 만들기\n",
    "f=open('stopwords.txt','r',encoding='utf-8')\n",
    "stop_words = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dea8ba17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2344"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1776c59a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialize Komoran tokenizer\n",
    "okt = Okt()\n",
    "# Preprocessing function using KoNLPy2\n",
    "def preprocess_text(text, stop_words):\n",
    "    # Remove non-Korean characters and whitespace\n",
    "    text = re.sub(r'[^가-힣\\s]', '', text)\n",
    "    # Tokenize the text using Komoran\n",
    "    pos_tags = okt.pos(text)\n",
    "    filtered_words = [word for word, pos in pos_tags if pos in [\"Noun\", \"Adjective\", \"Verb\"]]\n",
    "    # Remove stopwords\n",
    "    words = [word for word in filtered_words if word not in stop_words]\n",
    "    return words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48bcf55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF 점수 계산하기\n",
    "def compute_tfidf_scores_v2(text, stop_words, preprocess_func):\n",
    "# text를 문장 단위로 분해하기\n",
    "    sentences = re.split(r'(?<!\\w\\.\\w.)(?<![A-Z][a-z]\\.)(?<=\\.|\\?)\\s', text)\n",
    "    sentences = [s for s in sentences if len(s) > 0]\n",
    "    \n",
    "# 미리 정의한 전처리 함수를 통해 단어 단위로 토큰화 후 TF-IDF 계산 함수 정의\n",
    "# x에는 문장이 들어감\n",
    "    vectorizer = TfidfVectorizer(tokenizer=lambda x: preprocess_func(x, stop_words))\n",
    "# 문장 단위로 TF-IDF 점수 계산 및 매트릭스에 저장\n",
    "# 행이 문장, 열은 단어 - 즉, 특정 문장에 있는 특정 단어 별 tf-idf 점수가 값\n",
    "# TF : 문장에서 단어  / IDF : 문단에서 문장\n",
    "    tfidf_matrix = vectorizer.fit_transform(sentences)\n",
    "# TF-IDF가 계산된 단어 목록\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "# TFIDF 매트릭스에서 같은 단어의 점수들을 모두 합산해서 도출   \n",
    "    tfidf_scores = {}\n",
    "    for word in feature_names:\n",
    "        tfidf_scores[word] = np.sum(tfidf_matrix[:, vectorizer.vocabulary_[word]])\n",
    "        \n",
    "    return tfidf_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d229af07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 단어 그래프 생성\n",
    "def word_graph_with_tfidf(words, tfidf_scores, graph):\n",
    "    window_size = 3\n",
    "    for idx, word in enumerate(words):\n",
    "        if word not in graph:\n",
    "            graph.add_node(word, weight=tfidf_scores.get(word, 1))  # Using TF-IDF score as weight\n",
    "        for j in range(idx+1, idx+window_size):\n",
    "            if j < len(words):\n",
    "                if words[j] not in graph:\n",
    "                    graph.add_node(words[j], weight=tfidf_scores.get(words[j], 1))  # Using TF-IDF score as weight\n",
    "                graph.add_edge(word, words[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "83789b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 텍스트 랭킹 함수\n",
    "def text_ranking(graph, d=0.85, max_iter=50):\n",
    "# 주어진 그래프를 행렬로 변환 각 요소의 값은 노드 간 가중치\n",
    "    matrix = nx.to_numpy_matrix(graph)\n",
    "# 노드 개수 계산\n",
    "    num_of_words = graph.number_of_nodes()\n",
    "# 모든 노드의 초기 랭크를 같게 함\n",
    "    ranks = np.ones(num_of_words) / num_of_words\n",
    "# text_rank 알고리즘 실행\n",
    "    for _ in range(max_iter):\n",
    "        new_ranks = (1-d) + d * matrix.T.dot(ranks.reshape(-1,1))\n",
    "        if np.linalg.norm(new_ranks - ranks, 2) < 1e-8:\n",
    "            break\n",
    "        ranks = new_ranks\n",
    "# 결과 반환\n",
    "    word_ranks = {word: rank for word, rank in zip(graph.nodes(), ranks)}\n",
    "    sorted_word_ranks = sorted(word_ranks.items(), key=lambda x: x[1], reverse=True)\n",
    "    keywords = [word for word, rank in sorted_word_ranks]\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "48e61ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 생성\n",
    "graph = nx.Graph()\n",
    "\n",
    "words = preprocess_text(text, stop_words)\n",
    "\n",
    "tfidf_scores = compute_tfidf_scores_v2(text, stop_words, preprocess_text)\n",
    "\n",
    "word_graph_with_tfidf(words, tfidf_scores, graph)\n",
    "\n",
    "keywords = text_ranking(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "02ad5f43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "403\n"
     ]
    }
   ],
   "source": [
    "print(len(keywords))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4abd1d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['스', '사피', '인간', '인류', '출', '간', '책', '저자', '서문', '더', '특별', '이제', '할', '이해', '한다', '인공', '지능', '시대', '세상', '동료', '나아갈', '마음', '전하', '통찰', '명실', '역사', '인문', '가로지르는', '미래', '작', '호소', '풍부한', '없었다', '호모', '읽고', '있어', '시장', '제작', '추천', '지식', '리', '사랑', '통해', '수', '글', '종횡무진', '주년', '이후', '강조', '상부']\n"
     ]
    }
   ],
   "source": [
    "print(keywords[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2793aed",
   "metadata": {},
   "source": [
    "### 생각한대로 나오지는 않는다.."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
